# wine-clustering-exercise
---

## ğŸ· Wine Clustering with K-Means and PCA

Bu proje, ÅŸaraplarÄ±n kimyasal Ã¶zelliklerine dayanarak benzerliklerine gÃ¶re gruplandÄ±rÄ±lmasÄ±nÄ± (kÃ¼melenmesini) amaÃ§lamaktadÄ±r. Proje, veri Ã¶n iÅŸleme, kÃ¼me sayÄ±sÄ±nÄ± belirleme ve kÃ¼meleme sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirme adÄ±mlarÄ±nÄ± iÃ§ermektedir.

### ğŸ“Š Veri Seti
Ã‡alÄ±ÅŸmada kullanÄ±lan veri seti, Kaggle'dan elde edilen ve farklÄ± ÅŸaraplarÄ±n kimyasal analiz sonuÃ§larÄ±nÄ± iÃ§eren bir veri setidir. Veri seti, Alkol, Malic Acid, Proline gibi toplam 13 farklÄ± Ã¶zellik (feature) barÄ±ndÄ±rmaktadÄ±r.

### ğŸ› ï¸ Proje AdÄ±mlarÄ± ve Uygulanan Metodlar

#### 1. Veri KeÅŸfi ve Ã–n Ä°ÅŸleme
Projenin ilk aÅŸamasÄ±nda veri setinin temel yapÄ±sÄ± incelenmiÅŸtir. `df.info()` ve `df.describe()` gibi metotlarla eksik veri, veri tipleri ve temel istatistikler kontrol edilmiÅŸtir. Eksik veri olmadÄ±ÄŸÄ± tespit edilmiÅŸtir.
Ek olarak, Ã¶zellikler arasÄ±ndaki iliÅŸkileri anlamak iÃ§in bir **korelasyon matrisi** oluÅŸturulmuÅŸtur. Bu matris, `Proline` ve `Alcohol` gibi bazÄ± Ã¶zellikler arasÄ±nda yÃ¼ksek pozitif korelasyonlar olduÄŸunu gÃ¶stermektedir. Bu analiz, veri yapÄ±sÄ±nÄ± anlamak iÃ§in Ã¶nemli bir ilk adÄ±mdÄ±r.
### Korelasyon Matrisi
![Korelasyon Matrisi](Figure_1.png)


#### 2. Standardizasyon
Veri setindeki Ã¶zelliklerin farklÄ± Ã¶lÃ§eklerde olmasÄ±, kÃ¼meleme algoritmasÄ±nÄ±n performansÄ±nÄ± etkileyebilir. Bu nedenle, tÃ¼m Ã¶zellikler **`StandardScaler`** kullanÄ±larak standardize edilmiÅŸtir. Bu iÅŸlem, ortalamayÄ± 0 ve standart sapmayÄ± 1'e getirerek verinin K-Means gibi mesafe tabanlÄ± algoritmalara uygun hale gelmesini saÄŸlar.

#### 3. Optimum KÃ¼me SayÄ±sÄ±nÄ± Belirleme
K-Means algoritmasÄ± iÃ§in en uygun kÃ¼me sayÄ±sÄ±nÄ± belirlemek kritik bir adÄ±mdÄ±r. Bu projede iki farklÄ± yÃ¶ntem kullanÄ±lmÄ±ÅŸtÄ±r:

* **Elbow Metodu:** Bu metot, farklÄ± kÃ¼me sayÄ±larÄ± iÃ§in **inertia** (kÃ¼me iÃ§i toplam kareler sapmasÄ±) deÄŸerini gÃ¶rselleÅŸtirir. Grafikteki "dirsek" noktasÄ±nÄ± bularak en uygun kÃ¼me sayÄ±sÄ±na karar verilir.
YukarÄ±daki grafikte, `k=3`'ten sonra eÄŸimin belirgin bir ÅŸekilde azaldÄ±ÄŸÄ± gÃ¶rÃ¼lmektedir. Bu da optimum kÃ¼me sayÄ±sÄ±nÄ±n **3** olabileceÄŸini iÅŸaret etmektedir.

* **Silhouette Skoru:** Her bir Ã¶rneÄŸin kendi kÃ¼mesi iÃ§indeki uyumunu ve diÄŸer kÃ¼melerden ne kadar ayrÄ±ldÄ±ÄŸÄ±nÄ± Ã¶lÃ§en bir metriktir. 2 ile 10 kÃ¼me sayÄ±sÄ± arasÄ±ndaki denemelerde en yÃ¼ksek skor `k=3` ve `k=2` deÄŸerleri iÃ§in elde edilmiÅŸtir.
Her iki metodun sonuÃ§larÄ± da `k=3` kÃ¼me sayÄ±sÄ±nÄ±n makul bir seÃ§im olduÄŸunu gÃ¶stermektedir.

### Elbow Metodu
![Elbow Metodu](Figure_2.png)


#### 4. K-Means KÃ¼melemesi ve GÃ¶rselleÅŸtirme
SeÃ§ilen 3 kÃ¼me sayÄ±sÄ± ile **K-Means** algoritmasÄ± standardize edilmiÅŸ veri Ã¼zerinde Ã§alÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r. KÃ¼meleme sonuÃ§larÄ±nÄ± iki boyutlu bir dÃ¼zlemde gÃ¶rselleÅŸtirmek iÃ§in **Principal Component Analysis (PCA)** kullanÄ±lmÄ±ÅŸtÄ±r. PCA, veri setinin boyutunu en Ã¶nemli iki bileÅŸene (PCA 1 ve PCA 2) indirgeyerek veriyi daha kolay yorumlanabilir hale getirir.
GÃ¶rselleÅŸtirme, ÅŸaraplarÄ±n Ã¼Ã§ farklÄ± gruba baÅŸarÄ±yla ayrÄ±ldÄ±ÄŸÄ±nÄ± aÃ§Ä±kÃ§a gÃ¶stermektedir. KÃ¼me 0, 1 ve 2 olarak etiketlenen bu gruplar, kimyasal Ã¶zelliklerine gÃ¶re birbirlerinden belirgin ÅŸekilde farklÄ±laÅŸmaktadÄ±r.

### Principal Component Analysis (PCA)
![Temel BileÅŸen Analizi (PCA)](Figure_3.png)

### ğŸ¯ SonuÃ§lar
Projenin sonunda, her bir kÃ¼menin ortalama Ã¶zellik deÄŸerleri incelenerek her kÃ¼menin kendine Ã¶zgÃ¼ karakteristiÄŸi belirlenmiÅŸtir. Bu analiz, kÃ¼meleme iÅŸleminin yalnÄ±zca veri noktalarÄ±nÄ± gruplamakla kalmayÄ±p, aynÄ± zamanda her bir grubun temel Ã¶zelliklerini ortaya Ã§Ä±kardÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.

* **KÃ¼me 0:** Bu kÃ¼medeki ÅŸaraplar, Ã¶zellikle yÃ¼ksek Alcohol, Proline ve Color_Intensity deÄŸerleriyle Ã¶ne Ã§Ä±kmaktadÄ±r. Bu Ã¶zellikler, bu kÃ¼medeki ÅŸaraplarÄ±n muhtemelen daha gÃ¼Ã§lÃ¼ ve yoÄŸun bir profile sahip olduÄŸunu gÃ¶stermektedir.

* **KÃ¼me 1:** Bu gruptaki ÅŸaraplar, yÃ¼ksek Flavanoids, Total_Phenols ve OD280/OD315_of_diluted_wines deÄŸerlerine sahiptir. Bu kimyasallar, genellikle kÄ±rmÄ±zÄ± ÅŸaraplarda bulunan tanen ve renk pigmentleri ile iliÅŸkilidir ve bu ÅŸaraplarÄ±n daha zengin ve karmaÅŸÄ±k bir yapÄ±ya sahip olduÄŸunu iÅŸaret eder.

* **KÃ¼me 2:** Bu kÃ¼me, diÄŸer gruplara gÃ¶re daha dÃ¼ÅŸÃ¼k Flavanoids ve Total_Phenols deÄŸerleri sergilerken, Malic_Acid ve Ash_Alcanity deÄŸerlerinin daha yÃ¼ksek olduÄŸu gÃ¶zlemlenmiÅŸtir. Bu profil, genellikle beyaz ÅŸaraplarÄ±n karakteristik Ã¶zelliklerine daha yakÄ±ndÄ±r.

Bu Ã§alÄ±ÅŸma, **gÃ¶zetimsiz Ã¶ÄŸrenme** (unsupervised learning) tekniklerinin veri setindeki gizli yapÄ±larÄ± keÅŸfetmek ve bu yapÄ±larÄ± anlamlÄ± gruplara ayÄ±rmak iÃ§in ne kadar gÃ¼Ã§lÃ¼ araÃ§lar olduÄŸunu ortaya koymaktadÄ±r. KÃ¼me ortalamalarÄ±nÄ± inceleyerek, her bir kÃ¼menin ne tÃ¼r bir ÅŸarabÄ± temsil ettiÄŸine dair deÄŸerli iÃ§gÃ¶rÃ¼ler elde edilmiÅŸtir.






# ENG
## ğŸ· Wine Clustering with K-Means and PCA
This project aims to group (cluster) wines based on their chemical properties. The project includes steps for data preprocessing, determining the number of clusters, and visualizing the clustering results.

### ğŸ“Š Dataset
The dataset used in this study is a wine dataset obtained from Kaggle, containing the results of chemical analyses of various wines. The dataset contains a total of 13 different features, such as Alcohol, Malic Acid, and Proline.

### ğŸ› ï¸ Project Steps and Methods Used
#### 1. Data Exploration and Preprocessing
In the first phase of the project, the basic structure of the dataset was examined. Missing data, data types, and basic statistics were checked using methods like df.info() and df.describe(). No missing data was found.

Additionally, a **correlation matrix** was created to understand the relationships between the features. This matrix shows high positive correlations between some features, such as Proline and Alcohol. This analysis is an important first step in understanding the data structure.
### Correlation Matrix
![Correlation Matrix](Figure_1.png)

#### 2. Standardization
The varying scales of the features in the dataset can affect the performance of the clustering algorithm. Therefore, all features were standardized using **'StandardScaler'**. This process brings the mean to 0 and the standard deviation to 1, making the data suitable for distance-based algorithms like K-Means.

#### 3. Determining the Optimal Number of Clusters
Determining the most suitable number of clusters for the K-Means algorithm is a critical step. Two different methods were used in this project:

* **Elbow Method:** This method visualizes the **inertia** (the sum of squared distances within clusters) for different numbers of clusters. The most suitable number of clusters is determined by finding the "elbow" point in the graph.

The graph above shows that the slope decreases significantly after k=3. This indicates that the optimal number of clusters could be **3**.

* **Silhouette Score:**  This is a metric that measures how well each sample fits within its own cluster and how well it is separated from other clusters. In the trials between 2 and 10 clusters, the highest scores were obtained for k=3 and k=2.

The results of both methods suggest that k=3 is a reasonable choice for the number of clusters.

### Elbow Method
![Elbow Method](Figure_2.png)

#### 4. K-Means Clustering and Visualization
With the chosen number of clusters as 3, the **K-Means** algorithm was run on the standardized data. **Principal Component Analysis (PCA)** was used to visualize the clustering results on a two-dimensional plane. PCA reduces the dimensionality of the dataset to its two most important components (PCA 1 and PCA 2), making the data easier to interpret.

The visualization clearly shows that the wines have been successfully separated into three distinct groups. These groups, labeled as Cluster 0, 1, and 2, are noticeably different from each other based on their chemical properties.

### Principal Component Analysis (PCA)
![Principal Component Analysis (PCA)](Figure_3.png)


# ğŸ¯ Results
At the end of the project, the average feature values of each cluster were examined to determine the unique characteristics of each cluster. This analysis shows that the clustering process not only groups data points but also reveals the core characteristics of each group.

* **Cluster 0:** The wines in this cluster stand out with particularly high values of Alcohol, Proline, and Color_Intensity. These properties suggest that the wines in this cluster likely have a stronger and more intense profile.

* **Cluster 1:** Wines in this group have high values of Flavanoids, Total_Phenols, and OD280/OD315_of_diluted_wines. These chemicals are typically associated with tannins and color pigments found in red wines, indicating that these wines have a richer and more complex structure.

* **Cluster 2:** This cluster shows lower values for Flavanoids and Total_Phenols compared to the other groups, while higher values for Malic_Acid and Ash_Alcanity were observed. This profile is generally closer to the characteristics of white wines.

This work demonstrates how powerful **unsupervised learning** techniques are for discovering hidden structures within a dataset and separating these structures into meaningful groups. By examining the cluster averages, valuable insights were gained into what type of wine each cluster represents.
